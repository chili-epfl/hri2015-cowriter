> Reviews of submission #2155: ""Those who can't do, teach": a Teachable
> Robotic Agent for Children Learning Handwriting"

We would like to thank each of the reviewers for contributing such time and their expertise to this review.
We address the reviewers' remarks below.

>    - One of the main contributions claimed by the authors, is the first
>    investigation of the use of robots in learning by teaching.  This
>    narrative will need to be significantly altered due to the presence of
>    prior work in this area, as listed in the reviews.  We recommend that
>    authors outline their plans for the relevant revisions in the rebuttal.

>    -- the authors should reduce their claims that the idea of the robot as a
>    learner is a novel contribution of this paper, given the citation above.
>    The work is sufficiently interesting without this in any case.

We did not intend to claim such a contribution, but we can understand how the misunderstanding can arise from the second-last paragraph and the missing related robotics work. Both will be modified. 

>    - Related work lacks any citations of research on teachable robots or
>    agents or even robots or agents that act as educational characters, which
>    is unacceptable. (I’m not counting the apparent self-citation.) A
>    further consequence of this issue is that novelty is not sufficiently
>    addressed by the authors. This work needs to be properly situated.

We agree and greatly appreciate the numerous provided pointers to the literature. 
After accordingly reconsidering the literature on learning by teaching in robotics -- that we will appropriately present --, it
appears that learning by teaching applied to a task with a physical component is still 100% novel.

>    The presentation is the largest issue with this paper. Issues with
>    examples are below.
>
>    - highly verbose (and often redundant)-
>
>    I think that this paper could be condensed to a 5-page paper without
>    losing any content. Doing so should also dramatically increase its
>    readability. Some examples of how writing could become more concise and
>    clearer are below.

>    - vague writing -
>
>    “provides context for robotics in education” - What is meant by
>    context here?
DONE

>
>    “which is capable of generating the necessary letter models” -
>    Necessary according to what criteria?
DONE


All points have been well taken and the feedback will be incorporated to improve readability.

>    Also, I recommend removing “Those who cannot do, teach” from the
>    title. This phrase is an insult to teachers, and it’s unclear how
>    it’s relevant to this work.

The title was meant to re-purpose the idiom in the context of children with handwriting difficulties having an opportunity to improve through teaching. We appreciate this reviewer bringing to light the potential for this to strike a nerve with teachers and will accept their recommendation. 

>    The weaknesses of the paper lay in the part, in which the results of the
>    interaction study are reported. Unfortunately, the presentation lacks any
>    standards. I got the impression that the analyses are ongoing. Only for
>    some observations (duration of a session), descriptive statistics are
>    provided.

We have provided also the number of demonstrations for each group, and have refrained from reading further into the data because a full study with large sample sizes has not been completed. The work presented was intended for verification of the technical soundness of the system with children, in line with the theme.

>    The authors do not assess how educational their system is. I can accept
>    that at this point in the research, which seems sufficient for a
>    conference publication. Instead, they attempt to validate the components
>    of their system. There is much to like in this validation: robot
>    interaction with a good number of children, adjustments to system design
>    based on observations, and autonomous interaction was largely successful
>    (i.e., didn’t need interventions unless robot fell over).
>
>    However, there are considerable issues with the methods and conclusions
>    within this validation.
>
>    (1) The authors claim their system can generate letters with
>    “inappropriate internal proportions” and “global deformations”
>    (which need definitions) based on the analysis described as follows:
>    “It would be reasonable to consider the shapes in Figure 2 in the same
>    general categories.” Calling something reasonable does not make it so.
>    The authors then make the unjustified claim that “sufficient
>    capabilities… have been demonstrated.”

We agree that this was a wording issue on our part and will make reference to the classification methods used in previous work to determine such categories, and the confirmation that was received by teachers that the deformations are similar to childrens'.

>    (2) To assess whether the children believed that the letter-writing
>    trajectories shown on the tablet were being created by the robot, the
>    children were asked whether the robot could write its own name. This
>    question does not directly address believability, and there are plausible
>    interpretations of a “yes” answer that do not include the child
>    believing that the robot wrote what he or she saw on the tablet. For
>    instance, the child might think that the robot can write well but did not
>    actually write during the interaction. Thus, believability has not been
>    validated sufficiently. (Also, I recommend never saying that something is
>    generally “proven” when based on a limited sample.)

We agree with the points raised: it is a limitation of the question, which we imposed ourselves to avoid putting words in the children's mouths if we were to ask directly if the robot's writing was believable. Our argument is that at no point in the interaction did any child express that they did not believe that the robot was writing itself, even in a situation where they could have said "well, it's not *really* writing". We accept that we cannot conclude that the children believed it was writing, and will reword the outcome to instead be that no child ever expressed that they did not believe it was writing.

>    (3) “For example, for the model shown in Figure 1, the parameters may
>    represent the height of the top half of the letter compared to the bottom
>    half, the width of the overall shape, etc. Consequently, the shape
>    modelling process has produced the desired outcomes of parameterising the
>    shapes in ways which are able to be used to deform them meaningfully.”
>    - The author’s subjective appraisal of what variations are captured by
>    PCA is insufficient to claim the the deformations are meaningful.
>    Further, the word “meaningful” lacks grounding (what exactly does it
>    mean here)?
DONE
The deformations are meaningful in the sense that if a teacher wishes to create initial letters with a particular feature (a 'd' with a large loop, for example), it is possible with this system. We will clarify that it is the ability to create varied levels of deformations which may be ascribed descriptive interpretations (not just numerical) that is the desired outcome.

>    Additionally, more information is needed about the evaluation. How was
>    the initial parameter vector for a letter drawn? 
DONE

>    With what wording were
>    children asked whether they believed “the robot was learning and that
>    they were the ones teaching it”? 

Initial parameters were drawn from a range chosen to generate shapes for letters 'e' and 's' which would elicit correction. For the other letters, parameters were fixed, generating shapes which some groups chose to correct (e.g. 13/14 for 'n' and 2/14 for 'c'). We agree that more detail is to be included about the wording of the questions to support the claims, and can include the information on both.

>    The authors do a good job of citing related work on the educational side
>    of their work. However, the paper must situate itself amongst other work
>    on robots and simulated agents that act as teachers, pupils, or
>    educational companions.
>
>    Relevant work includes Justin Werfel’s paper “Embodied Teachable
>    Agents: Learning by Teaching Robots”, Knox and Stone’s IJSR 2012
>    paper How Humans Teach Agents (which discusses the benefits of using
>    computational agents in lieu of human confederates in studies),
>    Tanaka’s “Children teach a care-receiving robot to promote their
>    learning: Field experiments in a classroom for vocabulary learning.”,
>    and Chase et al.’s “Teachable Agents and the Protege Effect…”.
>
>    On robots that interact educationally with people, there’s Kanda et
>    al.’s “Interactive robots as social partners and peer tutors for
>    children”, Kory and Breazeal’s “Storytelling with robots: Learning
>    companions for preschool children’s language development”, Leyzberg
>    et al.’s “Personalizing robot tutors to individuals’ learning
>    differences”, Chang et al.’s “Exploring the possibility of using
>    humanoid robots as instructional tools for teaching a second language in
>    primary school”, Johnson et al.’s “Design and early evaluation of
>    the rubi-5 sociable robots”, and Movellan et al.’s “Sociable robot
>    improves toddler vocabulary skills”.

Again, we agree and will comply, and would like to thank the reviewer for their time in compiling this list.

>    - The authors appear to violate double-blindness in up to 3 ways: by
>    providing a URL to their code that contains “EPFL”, an apparent self
>    citation “Learning to write with a robot” from EPFL (given that this
>    paper claims to be the “first known robotic partner which children can
>    teach handwriting”, I assume that this citation is the same project),
>    and an apparent experimenter’s face appearing in Figure 8.

This was an oversight on our side and we apologise for letting it go undetected.

>    “a shape center of 0” - What’s really meant here is that the
>    normalized trajectory points average 0, correct? (If so, this quotation
>    is both vague and incorrect, since the trajectory and the shape it makes
>    are not the same thing.)
DONE
We can clarify that we indeed refer to a shape with its centre at the origin, not 0-average trajectory.

>    - overuse of actor removal -
>
>    Perhaps in an attempt to strike a scholarly tone, the authors often
>    remove themselves as actors. There is some precedent for this in academic
>    writing, but here (and most places) it leads to ambiguity, a lack of
>    energy in the writing, and difficult-to-parse writing.
>
>    “The following conclusions were successfully drawn” - By whom? Easier
>    to read and more honest: “We drew the following conclusions”
>
>    “It was reasoned” -> “We reasoned”
>
>    “While it is expected that” -> “We expect that”
>
>    Honestly, I don’t actually know for sure who was doing the reasoning or
>    reporting their expectations above. I just assume it’s the authors. But
>    I don’t know because they removed the actor in these sentences.
>
>    - includes numerous poorly justified assertions and some bad logic -
>
>    Some larger examples are already in the Soundness section above, but
>    there are many smaller examples as well.
>
>    “experimentally proven to provide convincing scaffolding” -
>    Convincing according to what metric? Also, scaffolding itself was never
>    even mentioned before this (and thus was not actually assessed).
>
>    “tablet-based application, which children are increasingly recognizing
>    as a disposable technology.” This is a strong claim that lacks any
>    evidence or argumentation. It’s not even clear what it means for an app
>    to be “disposable”.
>
>    In point #2 at the end of the first page, the authors imply that a robot
>    can draw a letter but an app can only show it in a completely drawn state
>    (not draw it along a trajectory at handwriting speed), which is false.
>
>    - many long sentences that are difficult to read -
>
>    “With some of the challenges towards an engaging long- term handwriting
>    intervention with the teachable robotic partner addressed, further steps
>    can be made towards an- swering the central question of what impact to
>    the outcomes of interventions the addition of such a teachable robotic
>    agent would have, including the effect on the participants’
>    self-esteem, motivation, and learning gains.”
>
>    The last two bullets on the final page are much too long and difficult to
>    read.
>
>    Long sentences should be broken up for readability.
>
>    - definitions needed -
>
>    protege effect, inappropriate internal proportions, global deformations

We agree with each of the points made; they will be addressed.

>    The work is very sound, although it's unclear which parts of the shape
>    modeling algorithm are novel.  This review is written under the
>    assumption that the idea of shape modeling is not novel, but that using
>    the model to generate "bad" examples is.  Otherwise, the system design
>    and evaluation are excellent.
DONE
This is accurate and will be clarified in the section on the shape modeling algorithm.

>    -- as mentioned above, the authors should consider reducing the space
>    dedicated to the synchronization (a technical challenge, to be sure, but
>    not especially interesting from a research perspective) and dedicate more
>    attention to the studies.

We believe the technical details to be relevant for those wishing to replicate the new technology presented.

>    -- the authors might address how their system can deal with and/or
>    produce mistakes that aren't just deformations; e.g. writing a letter
>    backwards.

We agree that this is interesting future work; it has been mentioned on page 7.

>    The presentation of the results needs to be revised. I suggest that the
>    authors specify information about: (i) the participants (what age groups
>    were interacting with the robot) and (ii) the procedure (by referring to
>    Figure 8).
>    Another problem is that as the results are presented now, it seems like
>    no dependent measures were taken. In one observation, the authors refer
>    to the children’s responses but they never mention how many children
>    provided this kind of answer. With respect to the different age groups
>    that interacted, the authors need to either to focus on one in their
>    results or to analyze how the interaction differed in these groups.

It will be more clearly stated that the results presented were from the 7-8yr age group only, not those aged 6-7 in the pilot study.

>    For the robot-drawn letters that were
>    not “in response to demonstrations from the children”, were they all
>    from new words?
DONE
Yes, we will clarify.

